# ğŸŒ¸ Iris Flower Classification - Complete Machine Learning Tutorial

A comprehensive machine learning tutorial that demonstrates the complete workflow of building a classification model using the famous Iris dataset. This project covers everything from data exploration to model deployment.

## ğŸ¯ Project Overview

This project implements multiple machine learning algorithms to classify iris flowers into three species:
- **Setosa** ğŸŒº
- **Versicolor** ğŸŒ¸
- **Virginica** ğŸŒ·

The tutorial demonstrates best practices in machine learning including data preprocessing, model comparison, hyperparameter tuning, and model persistence.

## ğŸ“Š Dataset

The Iris dataset contains 150 samples with 4 features:
- **Sepal Length** (cm)
- **Sepal Width** (cm)
- **Petal Length** (cm)
- **Petal Width** (cm)

**Dataset Characteristics:**
- 150 samples total
- 3 classes (50 samples each)
- 4 numerical features
- No missing values
- Perfectly balanced dataset

## ğŸš€ Features

### Machine Learning Pipeline
- âœ… **Data Loading & Exploration** - Comprehensive EDA with visualizations
- âœ… **Data Preprocessing** - Feature scaling and label encoding
- âœ… **Model Training** - Multiple algorithms comparison
- âœ… **Model Evaluation** - Cross-validation and performance metrics
- âœ… **Hyperparameter Tuning** - Grid search optimization
- âœ… **Feature Importance** - Analysis of most predictive features
- âœ… **Model Persistence** - Save/load trained models

### Algorithms Implemented
1. **Logistic Regression**
2. **Decision Tree**
3. **Random Forest**
4. **Support Vector Machine (SVM)**
5. **K-Nearest Neighbors (KNN)**
6. **Naive Bayes**

### Visualizations
- Feature distribution plots
- Correlation heatmap
- Feature importance charts
- Model performance comparisons

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.7+
- pip package manager

### Setup Instructions

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/iris-classification-tutorial.git
   cd iris-classification-tutorial
   ```

2. **Create a virtual environment (recommended)**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ® Usage

### Running the Complete Tutorial
```bash
python iris_classification_tutorial.py
```

### Using the Trained Model
```python
import joblib
import numpy as np

# Load saved model components
model = joblib.load('iris_classifier_random_forest_20241206.pkl')
scaler = joblib.load('iris_scaler_20241206.pkl')
encoder = joblib.load('iris_label_encoder_20241206.pkl')

# Make prediction on new data
new_flower = np.array([[5.8, 2.7, 5.1, 1.9]])
new_flower_scaled = scaler.transform(new_flower)
prediction = model.predict(new_flower_scaled)
species = encoder.inverse_transform(prediction)

print(f"Predicted species: {species[0]}")
```

### Interactive Jupyter Notebook
```bash
jupyter notebook iris_classification_notebook.ipynb
```

## ğŸ“ˆ Model Performance

| Algorithm | Test Accuracy | CV Score |
|-----------|---------------|----------|
| Random Forest | 96.67% | 95.83% Â± 0.04 |
| SVM | 96.67% | 95.83% Â± 0.04 |
| Logistic Regression | 96.67% | 95.00% Â± 0.05 |
| KNN | 96.67% | 95.00% Â± 0.05 |
| Decision Tree | 93.33% | 93.33% Â± 0.05 |
| Naive Bayes | 96.67% | 95.00% Â± 0.05 |

## ğŸ“ Project Structure

```
iris-classification-tutorial/
â”œâ”€â”€ README.md                           # Project documentation
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ iris_classification_tutorial.py    # Main tutorial script
â”œâ”€â”€ iris_classification_notebook.ipynb # Jupyter notebook version
â”œâ”€â”€ src/                               # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py                 # Data loading utilities
â”‚   â”œâ”€â”€ preprocessor.py                # Data preprocessing
â”‚   â”œâ”€â”€ models.py                      # Model definitions
â”‚   â”œâ”€â”€ evaluator.py                   # Model evaluation
â”‚   â””â”€â”€ utils.py                       # Utility functions
â”œâ”€â”€ data/                              # Data directory
â”‚   â”œâ”€â”€ raw/                           # Raw datasets
â”‚   â””â”€â”€ processed/                     # Processed datasets
â”œâ”€â”€ models/                            # Saved model files
â”œâ”€â”€ results/                           # Results and outputs
â”‚   â”œâ”€â”€ figures/                       # Generated plots
â”‚   â””â”€â”€ reports/                       # Analysis reports
â”œâ”€â”€ tests/                             # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data_loader.py
â”‚   â”œâ”€â”€ test_preprocessor.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ docs/                              # Documentation
â”‚   â”œâ”€â”€ api_reference.md
â”‚   â””â”€â”€ tutorial.md
â”œâ”€â”€ scripts/                           # Utility scripts
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ predict.py
â”œâ”€â”€ .github/                           # GitHub workflows
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml
â”œâ”€â”€ docker/                            # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â””â”€â”€ config/                            # Configuration files
    â”œâ”€â”€ config.yaml
    â””â”€â”€ logging.conf
```

## ğŸ¤– API Reference

### Core Functions

#### `load_and_explore_data()`
Loads the Iris dataset and performs exploratory data analysis.

**Returns:**
- `DataFrame`: Preprocessed iris dataset
- `dict`: Dataset statistics and information

#### `train_models(X_train, y_train, X_test, y_test)`
Trains multiple classification models and compares performance.

**Parameters:**
- `X_train`: Training features
- `y_train`: Training labels
- `X_test`: Test features
- `y_test`: Test labels

**Returns:**
- `dict`: Model performance results

#### `tune_hyperparameters(model, param_grid, X_train, y_train)`
Performs grid search hyperparameter tuning.

**Parameters:**
- `model`: Base model to tune
- `param_grid`: Parameter search space
- `X_train`: Training features
- `y_train`: Training labels

**Returns:**
- `object`: Best tuned model

## ğŸ§ª Testing

Run the test suite:
```bash
# Run all tests
python -m pytest tests/

# Run with coverage
python -m pytest tests/ --cov=src --cov-report=html

# Run specific test
python -m pytest tests/test_models.py
```

## ğŸ³ Docker Support

### Build and run with Docker:
```bash
# Build the image
docker build -t iris-classifier .

# Run the container
docker run -it iris-classifier

# Run with Docker Compose
docker-compose up
```

## ğŸ“š Learning Objectives

After completing this tutorial, you will understand:

### Machine Learning Fundamentals
- Data exploration and visualization techniques
- Feature engineering and preprocessing
- Train/validation/test split strategies
- Cross-validation for model selection
- Overfitting and underfitting concepts

### Classification Algorithms
- How different algorithms work
- When to use each algorithm
- Hyperparameter tuning strategies
- Model evaluation metrics

### Best Practices
- Code organization and modularity
- Version control with Git
- Documentation and reproducibility
- Model deployment preparation

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Code Style
- Follow PEP 8 guidelines
- Use meaningful variable names
- Add docstrings to functions
- Write unit tests for new features

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Iris Dataset**: Originally collected by Edgar Anderson and made famous by Ronald Fisher
- **Scikit-learn**: For providing excellent machine learning tools
- **Matplotlib & Seaborn**: For beautiful data visualizations
- **Pandas & NumPy**: For data manipulation and numerical computing

## ğŸ“ Contact

**Sakshi Sahu ** - sakshi100sahu@gmail.com

Project Link: [https://github.com/Sakshi-Sahu1/CodeAlpha_-Iris-Flower-Classification](https://github.com/Sakshi-Sahu1/CodeAlpha_-Iris-Flower-Classification)

---

â­ **If you found this project helpful, please give it a star!** â­

*Happy Learning! ğŸ“*
